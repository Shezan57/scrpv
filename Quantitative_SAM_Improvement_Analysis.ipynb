{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025b8bf6",
   "metadata": {},
   "source": [
    "# Quantitative SAM Improvement Analysis\n",
    "## Measuring Performance Gain: YOLO-Only vs YOLO+SAM Hybrid\n",
    "\n",
    "This notebook evaluates the quantitative improvement that SAM 3 provides over YOLO-only baseline for PPE violation detection.\n",
    "\n",
    "**Metrics Measured:**\n",
    "- Precision, Recall, F1-Score\n",
    "- False Positive Reduction Rate\n",
    "- False Negative Reduction Rate  \n",
    "- Decision Path Distribution\n",
    "- Per-class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6664a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q ultralytics opencv-python-headless matplotlib seaborn pandas\n",
    "!pip install -q git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.sam import SAM3SemanticPredictor\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Paths - MODIFY THESE\n",
    "    YOLO_WEIGHTS = '/content/best.pt'  # Your trained YOLO model\n",
    "    SAM_WEIGHTS = '/content/sam3.pt'   # SAM 3 weights\n",
    "    TEST_IMAGES_DIR = '/content/test/images'  # Test images directory\n",
    "    GROUND_TRUTH_DIR = '/content/test/labels'  # Ground truth annotations\n",
    "    OUTPUT_DIR = '/content/results'\n",
    "    \n",
    "    # Detection parameters\n",
    "    CONFIDENCE_THRESHOLD = 0.4\n",
    "    IOU_THRESHOLD = 0.3\n",
    "    SAM_IMAGE_SIZE = 1024\n",
    "    \n",
    "    # Class mapping (adjust based on your trained model)\n",
    "    TARGET_CLASSES = {\n",
    "        'person': [0],      # Adjust these IDs\n",
    "        'helmet': [1],\n",
    "        'vest': [2],\n",
    "        'no_helmet': [3]\n",
    "    }\n",
    "    \n",
    "    # ROI parameters\n",
    "    HEAD_ROI_RATIO = 0.4\n",
    "    TORSO_START_RATIO = 0.2\n",
    "    TORSO_END_RATIO = 0.7\n",
    "\n",
    "config = Config()\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "print(\"‚öôÔ∏è Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "\n",
    "def parse_yolo_annotation(txt_path, img_width, img_height):\n",
    "    \"\"\"Parse YOLO format annotation\"\"\"\n",
    "    annotations = []\n",
    "    if not os.path.exists(txt_path):\n",
    "        return annotations\n",
    "    \n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            \n",
    "            class_id = int(parts[0])\n",
    "            x_center = float(parts[1]) * img_width\n",
    "            y_center = float(parts[2]) * img_height\n",
    "            width = float(parts[3]) * img_width\n",
    "            height = float(parts[4]) * img_height\n",
    "            \n",
    "            x_min = int(x_center - width / 2)\n",
    "            y_min = int(y_center - height / 2)\n",
    "            x_max = int(x_center + width / 2)\n",
    "            y_max = int(y_center + height / 2)\n",
    "            \n",
    "            annotations.append([class_id, x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate IoU between two boxes\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    if intersection == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def match_detections_to_ground_truth(detections, ground_truth, iou_threshold=0.5):\n",
    "    \"\"\"Match detected violations to ground truth\"\"\"\n",
    "    gt_violations = [gt for gt in ground_truth if gt[0] in config.TARGET_CLASSES['no_helmet']]\n",
    "    \n",
    "    matched_gt = set()\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    \n",
    "    for det in detections:\n",
    "        if not det['is_violation']:\n",
    "            continue\n",
    "        \n",
    "        det_box = det['bbox']\n",
    "        matched = False\n",
    "        \n",
    "        for idx, gt in enumerate(gt_violations):\n",
    "            if idx in matched_gt:\n",
    "                continue\n",
    "            \n",
    "            gt_box = gt[1:5]\n",
    "            iou = calculate_iou(det_box, gt_box)\n",
    "            \n",
    "            if iou >= iou_threshold:\n",
    "                true_positives += 1\n",
    "                matched_gt.add(idx)\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            false_positives += 1\n",
    "    \n",
    "    false_negatives = len(gt_violations) - len(matched_gt)\n",
    "    \n",
    "    return true_positives, false_positives, false_negatives\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, fp, fn):\n",
    "    \"\"\"Calculate precision, recall, F1\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9132f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO-Only Detector (Baseline)\n",
    "\n",
    "class YOLOOnlyDetector:\n",
    "    def __init__(self):\n",
    "        print(\"üîß Initializing YOLO-Only Baseline...\")\n",
    "        self.model = YOLO(config.YOLO_WEIGHTS)\n",
    "        print(\"‚úÖ YOLO-Only Baseline Ready\")\n",
    "    \n",
    "    def detect(self, image_path):\n",
    "        results = self.model.predict(image_path, conf=config.CONFIDENCE_THRESHOLD, verbose=False)\n",
    "        detections = []\n",
    "        for box in results[0].boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            coords = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            detections.append([cls, coords[0], coords[1], coords[2], coords[3], conf])\n",
    "        return detections\n",
    "    \n",
    "    def evaluate_violations(self, image_path):\n",
    "        detections = self.detect(image_path)\n",
    "        \n",
    "        persons = [d for d in detections if d[0] in config.TARGET_CLASSES['person']]\n",
    "        helmets = [d for d in detections if d[0] in config.TARGET_CLASSES['helmet']]\n",
    "        vests = [d for d in detections if d[0] in config.TARGET_CLASSES['vest']]\n",
    "        no_helmets = [d for d in detections if d[0] in config.TARGET_CLASSES['no_helmet']]\n",
    "        \n",
    "        violations = []\n",
    "        \n",
    "        for person in persons:\n",
    "            p_box = person[1:5]\n",
    "            has_helmet = False\n",
    "            has_vest = False\n",
    "            \n",
    "            for helmet in helmets:\n",
    "                if calculate_iou(p_box, helmet[1:5]) > config.IOU_THRESHOLD:\n",
    "                    has_helmet = True\n",
    "                    break\n",
    "            \n",
    "            for vest in vests:\n",
    "                if calculate_iou(p_box, vest[1:5]) > config.IOU_THRESHOLD:\n",
    "                    has_vest = True\n",
    "                    break\n",
    "            \n",
    "            for no_helmet in no_helmets:\n",
    "                if calculate_iou(p_box, no_helmet[1:5]) > config.IOU_THRESHOLD:\n",
    "                    has_helmet = False\n",
    "                    break\n",
    "            \n",
    "            is_violation = not has_helmet or not has_vest\n",
    "            \n",
    "            violations.append({\n",
    "                'bbox': p_box,\n",
    "                'has_helmet': has_helmet,\n",
    "                'has_vest': has_vest,\n",
    "                'is_violation': is_violation,\n",
    "                'confidence': person[5]\n",
    "            })\n",
    "        \n",
    "        return violations\n",
    "\n",
    "print(\"‚úÖ YOLOOnlyDetector class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86568f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Detector (YOLO + SAM)\n",
    "\n",
    "class HybridDetector:\n",
    "    def __init__(self):\n",
    "        print(\"üîß Initializing YOLO + SAM Hybrid System...\")\n",
    "        self.yolo_model = YOLO(config.YOLO_WEIGHTS)\n",
    "        overrides = dict(model=config.SAM_WEIGHTS, task=\"segment\", mode=\"predict\", conf=0.15)\n",
    "        self.sam_model = SAM3SemanticPredictor(overrides=overrides)\n",
    "        print(\"‚úÖ Hybrid System Ready\")\n",
    "    \n",
    "    def box_iou(self, box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        return inter / box2_area\n",
    "    \n",
    "    def run_sam_rescue(self, image_path, search_prompts, roi_box, h, w):\n",
    "        try:\n",
    "            res = self.sam_model(image_path, text=search_prompts, imgsz=config.SAM_IMAGE_SIZE, verbose=False)\n",
    "            if not res[0].masks:\n",
    "                return False\n",
    "            masks = [m.cpu().numpy().astype(np.uint8) for m in res[0].masks.data]\n",
    "            for m in masks:\n",
    "                if m.shape[:2] != (h, w):\n",
    "                    m = cv2.resize(m, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                roi = m[roi_box[1]:roi_box[3], roi_box[0]:roi_box[2]]\n",
    "                if np.sum(roi) > 0:\n",
    "                    return True\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "    \n",
    "    def evaluate_violations(self, image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_rgb.shape[:2]\n",
    "        \n",
    "        results = self.yolo_model.predict(image_path, conf=config.CONFIDENCE_THRESHOLD, verbose=False)\n",
    "        detections = {'person': [], 'helmet': [], 'vest': [], 'no_helmet': []}\n",
    "        \n",
    "        for box in results[0].boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            coords = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            for key, ids in config.TARGET_CLASSES.items():\n",
    "                if cls in ids:\n",
    "                    detections[key].append(coords)\n",
    "        \n",
    "        violations = []\n",
    "        \n",
    "        for p_box in detections['person']:\n",
    "            has_helmet, has_vest, unsafe_explicit = False, False, False\n",
    "            decision_path = \"\"\n",
    "            \n",
    "            for eq in detections['helmet']:\n",
    "                if self.box_iou(p_box, eq) > 0.3:\n",
    "                    has_helmet = True\n",
    "            for eq in detections['vest']:\n",
    "                if self.box_iou(p_box, eq) > 0.3:\n",
    "                    has_vest = True\n",
    "            for eq in detections['no_helmet']:\n",
    "                if self.box_iou(p_box, eq) > 0.3:\n",
    "                    unsafe_explicit = True\n",
    "            \n",
    "            if unsafe_explicit:\n",
    "                decision_path = \"Fast Violation\"\n",
    "                has_helmet = False\n",
    "            elif has_helmet and has_vest:\n",
    "                decision_path = \"Fast Safe\"\n",
    "            elif has_helmet and not has_vest:\n",
    "                decision_path = \"Rescue Body\"\n",
    "                body_roi = [p_box[0], int(p_box[1] + (p_box[3]-p_box[1])*0.2), p_box[2], p_box[3]]\n",
    "                has_vest = self.run_sam_rescue(image_path, [\"vest\"], body_roi, h, w)\n",
    "            elif has_vest and not has_helmet:\n",
    "                decision_path = \"Rescue Head\"\n",
    "                head_roi = [p_box[0], p_box[1], p_box[2], int(p_box[1] + (p_box[3]-p_box[1])*0.4)]\n",
    "                has_helmet = self.run_sam_rescue(image_path, [\"helmet\"], head_roi, h, w)\n",
    "            else:\n",
    "                decision_path = \"Critical\"\n",
    "                head_roi = [p_box[0], p_box[1], p_box[2], int(p_box[1] + (p_box[3]-p_box[1])*0.4)]\n",
    "                body_roi = [p_box[0], int(p_box[1] + (p_box[3]-p_box[1])*0.2), p_box[2], p_box[3]]\n",
    "                has_helmet = self.run_sam_rescue(image_path, [\"helmet\"], head_roi, h, w)\n",
    "                has_vest = self.run_sam_rescue(image_path, [\"vest\"], body_roi, h, w)\n",
    "            \n",
    "            is_violation = not has_helmet or not has_vest\n",
    "            \n",
    "            violations.append({\n",
    "                'bbox': p_box,\n",
    "                'has_helmet': has_helmet,\n",
    "                'has_vest': has_vest,\n",
    "                'is_violation': is_violation,\n",
    "                'decision_path': decision_path,\n",
    "                'confidence': 0.85\n",
    "            })\n",
    "        \n",
    "        return violations\n",
    "\n",
    "print(\"‚úÖ HybridDetector class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ceba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Quantitative Evaluation\n",
    "\n",
    "def run_evaluation():\n",
    "    print(\"=\"*80)\n",
    "    print(\"üî¨ QUANTITATIVE SAM IMPROVEMENT ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Initialize detectors\n",
    "    yolo_detector = YOLOOnlyDetector()\n",
    "    hybrid_detector = HybridDetector()\n",
    "    \n",
    "    # Get test images\n",
    "    test_images = glob.glob(f\"{config.TEST_IMAGES_DIR}/*.jpg\") + \\\n",
    "                  glob.glob(f\"{config.TEST_IMAGES_DIR}/*.png\") + \\\n",
    "                  glob.glob(f\"{config.TEST_IMAGES_DIR}/*.webp\")\n",
    "    \n",
    "    print(f\"\\nüì∏ Found {len(test_images)} test images\\n\")\n",
    "    \n",
    "    yolo_results = {'tp': 0, 'fp': 0, 'fn': 0}\n",
    "    hybrid_results = {'tp': 0, 'fp': 0, 'fn': 0}\n",
    "    decision_paths = []\n",
    "    detailed_results = []\n",
    "    \n",
    "    for idx, img_path in enumerate(test_images):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"   Processing image {idx+1}/{len(test_images)}...\")\n",
    "        \n",
    "        img_name = os.path.basename(img_path)\n",
    "        gt_path = os.path.join(config.GROUND_TRUTH_DIR, \n",
    "                               img_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.webp', '.txt'))\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        ground_truth = parse_yolo_annotation(gt_path, w, h)\n",
    "        \n",
    "        if len(ground_truth) == 0:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # YOLO-only\n",
    "            yolo_detections = yolo_detector.evaluate_violations(img_path)\n",
    "            yolo_tp, yolo_fp, yolo_fn = match_detections_to_ground_truth(yolo_detections, ground_truth)\n",
    "            yolo_results['tp'] += yolo_tp\n",
    "            yolo_results['fp'] += yolo_fp\n",
    "            yolo_results['fn'] += yolo_fn\n",
    "            \n",
    "            # Hybrid\n",
    "            hybrid_detections = hybrid_detector.evaluate_violations(img_path)\n",
    "            hybrid_tp, hybrid_fp, hybrid_fn = match_detections_to_ground_truth(hybrid_detections, ground_truth)\n",
    "            hybrid_results['tp'] += hybrid_tp\n",
    "            hybrid_results['fp'] += hybrid_fp\n",
    "            hybrid_results['fn'] += hybrid_fn\n",
    "            \n",
    "            for det in hybrid_detections:\n",
    "                if 'decision_path' in det:\n",
    "                    decision_paths.append(det['decision_path'])\n",
    "            \n",
    "            detailed_results.append({\n",
    "                'image': img_name,\n",
    "                'yolo_tp': yolo_tp, 'yolo_fp': yolo_fp, 'yolo_fn': yolo_fn,\n",
    "                'hybrid_tp': hybrid_tp, 'hybrid_fp': hybrid_fp, 'hybrid_fn': hybrid_fn\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return yolo_results, hybrid_results, decision_paths, detailed_results\n",
    "\n",
    "# Run evaluation\n",
    "yolo_results, hybrid_results, decision_paths, detailed_results = run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and Display Results\n",
    "\n",
    "yolo_prec, yolo_rec, yolo_f1 = calculate_metrics(yolo_results['tp'], yolo_results['fp'], yolo_results['fn'])\n",
    "hybrid_prec, hybrid_rec, hybrid_f1 = calculate_metrics(hybrid_results['tp'], hybrid_results['fp'], hybrid_results['fn'])\n",
    "\n",
    "prec_improvement = ((hybrid_prec - yolo_prec) / yolo_prec * 100) if yolo_prec > 0 else 0\n",
    "rec_improvement = ((hybrid_rec - yolo_rec) / yolo_rec * 100) if yolo_rec > 0 else 0\n",
    "f1_improvement = ((hybrid_f1 - yolo_f1) / yolo_f1 * 100) if yolo_f1 > 0 else 0\n",
    "fp_reduction = ((yolo_results['fp'] - hybrid_results['fp']) / yolo_results['fp'] * 100) if yolo_results['fp'] > 0 else 0\n",
    "fn_reduction = ((yolo_results['fn'] - hybrid_results['fn']) / yolo_results['fn'] * 100) if yolo_results['fn'] > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  YOLO-Only Baseline:\")\n",
    "print(f\"   Precision: {yolo_prec:.4f}\")\n",
    "print(f\"   Recall:    {yolo_rec:.4f}\")\n",
    "print(f\"   F1-Score:  {yolo_f1:.4f}\")\n",
    "print(f\"   TP: {yolo_results['tp']}, FP: {yolo_results['fp']}, FN: {yolo_results['fn']}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  YOLO + SAM Hybrid:\")\n",
    "print(f\"   Precision: {hybrid_prec:.4f} ({prec_improvement:+.2f}%)\")\n",
    "print(f\"   Recall:    {hybrid_rec:.4f} ({rec_improvement:+.2f}%)\")\n",
    "print(f\"   F1-Score:  {hybrid_f1:.4f} ({f1_improvement:+.2f}%)\")\n",
    "print(f\"   TP: {hybrid_results['tp']}, FP: {hybrid_results['fp']}, FN: {hybrid_results['fn']}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  SAM Improvement Metrics:\")\n",
    "print(f\"   False Positive Reduction: {fp_reduction:.2f}%\")\n",
    "print(f\"   False Negative Reduction: {fn_reduction:.2f}%\")\n",
    "print(f\"   Precision Improvement:    {prec_improvement:+.2f}%\")\n",
    "print(f\"   Recall Improvement:       {rec_improvement:+.2f}%\")\n",
    "print(f\"   F1-Score Improvement:     {f1_improvement:+.2f}%\")\n",
    "\n",
    "if decision_paths:\n",
    "    path_counts = Counter(decision_paths)\n",
    "    total = len(decision_paths)\n",
    "    print(\"\\n4Ô∏è‚É£  Decision Path Distribution:\")\n",
    "    for path in ['Fast Safe', 'Fast Violation', 'Rescue Head', 'Rescue Body', 'Critical']:\n",
    "        count = path_counts.get(path, 0)\n",
    "        pct = (count / total * 100) if total > 0 else 0\n",
    "        print(f\"   {path:20s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    sam_paths = ['Rescue Head', 'Rescue Body', 'Critical']\n",
    "    sam_count = sum([path_counts.get(p, 0) for p in sam_paths])\n",
    "    sam_rate = (sam_count / total * 100) if total > 0 else 0\n",
    "    print(f\"   {'SAM Activation Rate':20s}: {sam_count:4d} ({sam_rate:5.1f}%)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c89ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Comparison Visualization\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Metrics Comparison\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "yolo_vals = [yolo_prec, yolo_rec, yolo_f1]\n",
    "hybrid_vals = [hybrid_prec, hybrid_rec, hybrid_f1]\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "bars1 = ax1.bar(x - width/2, yolo_vals, width, label='YOLO Only', color='#FF6B6B', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, hybrid_vals, width, label='YOLO + SAM', color='#4ECDC4', alpha=0.8)\n",
    "ax1.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Performance Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.0)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Improvement Percentages\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "improvements = ['Precision', 'Recall', 'F1-Score']\n",
    "improvement_vals = [prec_improvement, rec_improvement, f1_improvement]\n",
    "colors = ['#2ECC71' if v > 0 else '#E74C3C' for v in improvement_vals]\n",
    "bars = ax2.barh(improvements, improvement_vals, color=colors, alpha=0.8)\n",
    "ax2.set_xlabel('Improvement (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('SAM Improvement Over YOLO-Only', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, improvement_vals)):\n",
    "    ax2.text(val + 1 if val > 0 else val - 1, i, f'{val:+.1f}%',\n",
    "            va='center', ha='left' if val > 0 else 'right', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. Error Reduction\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "error_types = ['False Positives', 'False Negatives']\n",
    "yolo_errors = [yolo_results['fp'], yolo_results['fn']]\n",
    "hybrid_errors = [hybrid_results['fp'], hybrid_results['fn']]\n",
    "x = np.arange(len(error_types))\n",
    "bars1 = ax3.bar(x - width/2, yolo_errors, width, label='YOLO Only', color='#FF6B6B', alpha=0.8)\n",
    "bars2 = ax3.bar(x + width/2, hybrid_errors, width, label='YOLO + SAM', color='#4ECDC4', alpha=0.8)\n",
    "ax3.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Error Reduction', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(error_types, rotation=15)\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Decision Path Distribution\n",
    "if decision_paths:\n",
    "    ax4 = fig.add_subplot(gs[1, :2])\n",
    "    path_counts = Counter(decision_paths)\n",
    "    paths = ['Fast Safe', 'Fast Violation', 'Rescue Head', 'Rescue Body', 'Critical']\n",
    "    counts = [path_counts.get(p, 0) for p in paths]\n",
    "    total = sum(counts)\n",
    "    percentages = [c/total*100 if total > 0 else 0 for c in counts]\n",
    "    colors_map = ['#2ECC71', '#E74C3C', '#F39C12', '#E67E22', '#8E44AD']\n",
    "    bars = ax4.bar(paths, percentages, color=colors_map, alpha=0.8)\n",
    "    for bar, pct in zip(bars, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{pct:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('Decision Path', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('Distribution of Decision Paths', fontsize=14, fontweight='bold')\n",
    "    ax4.axhline(y=15, color='blue', linestyle='--', label='Expected SAM Threshold', linewidth=2)\n",
    "    ax4.legend()\n",
    "    plt.setp(ax4.xaxis.get_majorticklabels(), rotation=15)\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Error Reduction Rate\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "reduction_labels = ['FP Reduction', 'FN Reduction']\n",
    "reduction_values = [fp_reduction, fn_reduction]\n",
    "colors_red = ['#2ECC71' if v > 0 else '#E74C3C' for v in reduction_values]\n",
    "bars = ax5.barh(reduction_labels, reduction_values, color=colors_red, alpha=0.8)\n",
    "ax5.set_xlabel('Reduction (%)', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Error Reduction Rate', fontsize=14, fontweight='bold')\n",
    "ax5.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax5.grid(axis='x', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, reduction_values)):\n",
    "    ax5.text(val + 2 if val > 0 else val - 2, i, f'{val:.1f}%',\n",
    "            va='center', ha='left' if val > 0 else 'right', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Quantitative SAM Improvement Analysis', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.savefig(f'{config.OUTPUT_DIR}/comparison_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Visualization saved to {config.OUTPUT_DIR}/comparison_plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b505ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "\n",
    "results_dict = {\n",
    "    'yolo_only': {\n",
    "        'precision': float(yolo_prec),\n",
    "        'recall': float(yolo_rec),\n",
    "        'f1_score': float(yolo_f1),\n",
    "        'tp': int(yolo_results['tp']),\n",
    "        'fp': int(yolo_results['fp']),\n",
    "        'fn': int(yolo_results['fn'])\n",
    "    },\n",
    "    'hybrid': {\n",
    "        'precision': float(hybrid_prec),\n",
    "        'recall': float(hybrid_rec),\n",
    "        'f1_score': float(hybrid_f1),\n",
    "        'tp': int(hybrid_results['tp']),\n",
    "        'fp': int(hybrid_results['fp']),\n",
    "        'fn': int(hybrid_results['fn'])\n",
    "    },\n",
    "    'improvement': {\n",
    "        'precision_improvement_pct': float(prec_improvement),\n",
    "        'recall_improvement_pct': float(rec_improvement),\n",
    "        'f1_improvement_pct': float(f1_improvement),\n",
    "        'fp_reduction_pct': float(fp_reduction),\n",
    "        'fn_reduction_pct': float(fn_reduction)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{config.OUTPUT_DIR}/quantitative_results.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "\n",
    "df = pd.DataFrame(detailed_results)\n",
    "df.to_csv(f'{config.OUTPUT_DIR}/detailed_results.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to:\")\n",
    "print(f\"   - {config.OUTPUT_DIR}/quantitative_results.json\")\n",
    "print(f\"   - {config.OUTPUT_DIR}/detailed_results.csv\")\n",
    "print(f\"   - {config.OUTPUT_DIR}/comparison_plots.png\")\n",
    "print(\"\\nüéâ Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
